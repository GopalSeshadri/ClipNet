{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "CAPTION_INPUT_SIZE = 300\n",
    "FRAME_INPUT_SIZE = 500\n",
    "CAPTION_LATENT_SIZE = 400\n",
    "FRAME_LATENT_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating placeholders\n",
    "caption_placeholder = tf.placeholder(tf.float32, shape = [None, None, CAPTION_INPUT_SIZE])\n",
    "frame_placeholder = tf.placeholder(tf.float32, shape = [None, None, FRAME_INPUT_SIZE])\n",
    "y_placeholder = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "# Setting GPU config\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.8)\n",
    "config = tf.ConfigProto(allow_soft_placement = True, gpu_options = gpu_options)\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Neural Network Graph for modified Siamese Network\n",
    "def train_caption_embeddings(x_placeholder, latent_dim):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(latent_dim, kernel_initializer = tf.contrib.layers.variance_scaling_initializer(), name = 'caption_cells')\n",
    "    cells = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = 0.5)\n",
    "    x, s = tf.nn.dynamic_rnn(cells, x_placeholder, dtype = tf.float32, swap_memory = True)\n",
    "    x = tf.contrib.layers.batch_norm(x, is_training = True, updates_collections = None)\n",
    "    x = tf.nn.dropout(x, rate = 0.2)\n",
    "    print(x.shape)\n",
    "    x = tf.reshape(x, shape = [-1, 50 * latent_dim])\n",
    "    print(x.shape)\n",
    "    x = tf.nn.dropout(x, rate = 0.2)\n",
    "    x = tf.layers.dense(x, latent_dim, kernel_initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    out = tf.nn.relu(x)\n",
    "    print(out.shape)\n",
    "    return out\n",
    "\n",
    "def train_frame_embeddings(x_placeholder, latent_dim):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(latent_dim, kernel_initializer = tf.contrib.layers.variance_scaling_initializer(), name = 'frame_cells')\n",
    "    cells = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = 0.5)\n",
    "    x, s = tf.nn.dynamic_rnn(cells, x_placeholder, dtype = tf.float32, swap_memory = True)\n",
    "    x = tf.contrib.layers.batch_norm(x, is_training = True, updates_collections = None)\n",
    "    x = tf.nn.dropout(x, rate = 0.2)\n",
    "    print(x.shape)\n",
    "    x = tf.reshape(x, shape = [-1, 50 * latent_dim])\n",
    "    print(x.shape)\n",
    "    x = tf.nn.dropout(x, rate = 0.2)\n",
    "    x = tf.layers.dense(x, latent_dim, kernel_initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    out = tf.nn.relu(x)\n",
    "    print(out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-88fb744a6a90>:2: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-88fb744a6a90>:4: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "(?, ?, 400)\n",
      "(?, 20000)\n",
      "WARNING:tensorflow:From <ipython-input-4-88fb744a6a90>:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "(?, 400)\n",
      "(?, ?, 500)\n",
      "(?, 25000)\n",
      "(?, 500)\n"
     ]
    }
   ],
   "source": [
    "caption_out = train_caption_embeddings(caption_placeholder, CAPTION_LATENT_SIZE) #Caption\n",
    "frame_out_full = train_frame_embeddings(frame_placeholder, FRAME_LATENT_SIZE) #Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the first CAPTION_LATENT_SIZE from frame latent vector\n",
    "frame_out = frame_out_full[:, :CAPTION_LATENT_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 400)\n"
     ]
    }
   ],
   "source": [
    "print(frame_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking cosine similarity\n",
    "normalize_caption = tf.nn.l2_normalize(caption_out, 0)        \n",
    "normalize_frame = tf.nn.l2_normalize(frame_out, 0)\n",
    "cos_similarity = tf.reduce_mean(tf.multiply(normalize_caption, normalize_frame), axis = 1)\n",
    "# cos_similarity = tf.reduce_mean(tf.multiply(caption_out, frame_out), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "print(cos_similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "final_out = tf.cast(tf.math.greater(tf.nn.sigmoid(cos_similarity), 0.5), tf.int16)\n",
    "accuracy = tf.metrics.accuracy(labels = y_placeholder, predictions = final_out)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = y_placeholder, logits = cos_similarity))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading triples list for training and validation\n",
    "with open(r'/home/login/Paired/train_triples_list.pickle', 'rb') as f:\n",
    "    train_triples_list = pickle.load(f)\n",
    "    \n",
    "with open(r'/home/login/Paired/val_triples_list.pickle', 'rb') as f:\n",
    "    val_triples_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anchor = np.stack([each[0] for each in train_triples_list], axis = 0)\n",
    "train_positive = np.stack([each[1] for each in train_triples_list], axis = 0)\n",
    "train_negative = np.stack([each[2] for each in train_triples_list], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(461750, 50, 300)\n",
      "(461750, 50, 500)\n",
      "(461750, 50, 500)\n"
     ]
    }
   ],
   "source": [
    "print(train_anchor.shape)\n",
    "print(train_positive.shape)\n",
    "print(train_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating pairs from triples\n",
    "\n",
    "train_triples_list, val_triples_list = [], []\n",
    "train_frame =  np.concatenate((train_positive, train_negative))\n",
    "\n",
    "train_positive, train_negative = [], []\n",
    "train_caption =  np.concatenate((train_anchor, train_anchor))\n",
    "train_anchor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating y list, it will be 1 for positive pairs 0 for negative pairs\n",
    "positive_y = [1] * int(train_frame.shape[0]/2)\n",
    "negative_y = [0] * int(train_frame.shape[0]/2)\n",
    "y = []\n",
    "y.extend(positive_y)\n",
    "y.extend(negative_y)\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(923500, 50, 300)\n",
      "(923500, 50, 500)\n",
      "923500\n"
     ]
    }
   ],
   "source": [
    "print(train_caption.shape)\n",
    "print(train_frame.shape)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triples_list, val_triples_list = [], []\n",
    "train_anchor, train_positive, train_negative = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 0 train loss is 2500.11\n",
      "After epoch 1 train loss is 2500.04\n",
      "After epoch 2 train loss is 2499.56\n",
      "After epoch 3 train loss is 2498.09\n",
      "After epoch 4 train loss is 2494.21\n",
      "After epoch 5 train loss is 2484.74\n",
      "After epoch 6 train loss is 2462.46\n",
      "After epoch 7 train loss is 2411.39\n",
      "After epoch 8 train loss is 2496.07\n",
      "After epoch 9 train loss is 2340.89\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "sess.run(init)\n",
    "for i in range(EPOCHS):\n",
    "    for idx in range(0, train_caption.shape[0], BATCH_SIZE):\n",
    "        train_caption_batch, train_frame_batch, y_batch = train_caption[idx : idx + BATCH_SIZE], train_frame[idx : idx + BATCH_SIZE], y[idx : idx + BATCH_SIZE]\n",
    "        sess.run(train, feed_dict = {caption_placeholder : train_caption_batch, \\\n",
    "                                     frame_placeholder : train_frame_batch, \\\n",
    "                                     y_placeholder : y_batch})\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "#         print(\"HELLLOOOO\")\n",
    "        tot_loss, val_tot_loss = 0, 0\n",
    "        for idx in range(0, train_caption.shape[0], BATCH_SIZE):\n",
    "            train_caption_batch, train_frame_batch, y_batch = train_caption[idx : idx + BATCH_SIZE], train_frame[idx : idx + BATCH_SIZE], y[idx : idx + BATCH_SIZE]\n",
    "            loss_ = sess.run(loss, feed_dict = {caption_placeholder : train_caption_batch, \\\n",
    "                                            frame_placeholder : train_frame_batch, \\\n",
    "                                            y_placeholder : y_batch})\n",
    "            tot_loss += loss_\n",
    "            \n",
    "#             val_anchor_batch, val_positive_batch, val_negative_batch = val_anchor[idx : idx + BATCH_SIZE], val_positive[idx : idx + BATCH_SIZE], val_negative[idx : idx + BATCH_SIZE]\n",
    "#             val_loss_ = sess.run(loss, feed_dict = {caption_placeholder : val_anchor_batch, \\\n",
    "#                                             frame_1_placeholder : val_positive_batch, \\\n",
    "#                                             frame_2_placeholder : val_negative_batch})\n",
    "#             val_tot_loss += val_loss_\n",
    "#         print(\"After epoch {} train loss is {:.4f} valid loss is {:.4f}\".format(i, tot_loss, val_tot_loss))\n",
    "        print(\"After epoch {} train loss is {:.2f}\".format(i, tot_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
